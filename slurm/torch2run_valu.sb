#!/bin/bash
#SBATCH --job-name=gYoloValu    ## Job 名稱
#SBATCH --mail-type=ALL            ## 收到通知條件
#SBATCH --mail-user=waue0920@gmail.com
#SBATCH --nodes=1                  ## 索取 x 個節點
#SBATCH --cpus-per-task=4          ## 每個 task 索取 x 顆 CPU
#SBATCH --gres=gpu:1               ## 每個節點索取 x 張 GPU
#SBATCH --account="GOV113038"      ## iService_ID 計畫 ID
#SBATCH --partition=gp1d          ## 使用測試 queue
#SBATCH --output=slurm-t2run_valu.log  ## 將標準輸出記錄到 log
#SBATCH --error=slurm-t2run_valu.log   ## 將錯誤輸出記錄到同一個 log

HOSTNAME=$(hostname | cut -d '.' -f 1)
echo "==================="
echo " !! Slurm Start  @ $HOSTNAME"
echo "-------------------"
# needed in H100
module purge
module load singularity

# sif
SIF=/work/waue0920/open_access/gyolo_ngc2306.sif
SINGULARITY="singularity run --nv $SIF"

# defind master
MASTER_ADDR=$(scontrol show hostname $SLURM_NODELIST | head -n 1)
export MASTER_ADDR

## twcc 不知為何SLURM_GPUS_ON_NODE 為空
nvidia-smi --list-gpus
NGPU=$(nvidia-smi -L | wc -l) # $SLURM_GPUS_ON_NODE
export NGPU


## 呼叫 yolo train torchrun 版本
# srun --gres=gpu:$SLURM_GPUS_ON_NODE --mpi=pmix $SINGULARITY bash yolotrain_segment.sh # SLURM_GPUS_ON_NODE 只有H100上才有

cmd="srun --gres=gpu:$NGPU --mpi=pmix $SINGULARITY bash gyolo_valu.sh"
echo "[$HOSTNAME]:  $cmd"
$cmd
